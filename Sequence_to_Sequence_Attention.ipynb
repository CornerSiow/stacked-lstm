{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CornerSiow/stacked-lstm/blob/main/Sequence_to_Sequence_Attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPSoqgoFKIok",
        "outputId": "4cc59095-1a8c-4828-dec8-bc7208b2700d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'stacked-lstm'...\n",
            "remote: Enumerating objects: 55, done.\u001b[K\n",
            "remote: Counting objects: 100% (55/55), done.\u001b[K\n",
            "remote: Compressing objects: 100% (53/53), done.\u001b[K\n",
            "remote: Total 55 (delta 25), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (55/55), 2.31 MiB | 2.33 MiB/s, done.\n",
            "Resolving deltas: 100% (25/25), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/CornerSiow/stacked-lstm.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTIvEGhUKSFU"
      },
      "outputs": [],
      "source": [
        "!cp /content/stacked-lstm/utility.py /content/utility.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afJOnVpZKUBA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import random\n",
        "import math\n",
        "from utility import showScore\n",
        "from utility import CustomDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7OG79DSnKYWF"
      },
      "outputs": [],
      "source": [
        "train_dataset = CustomDataset(\"/content/stacked-lstm/data/data_train.pickle\")\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
        "test_dataset = CustomDataset(\"/content/stacked-lstm/data/data_test.pickle\")\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztywW1M0K9ZM"
      },
      "outputs": [],
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Linear(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, input):\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        output, hidden = self.gru(embedded)\n",
        "        return output, hidden\n",
        "\n",
        "class BahdanauAttention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.Wa = nn.Linear(hidden_size, hidden_size)\n",
        "        self.Ua = nn.Linear(hidden_size, hidden_size)\n",
        "        self.Va = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, query, keys):\n",
        "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
        "        scores = scores.squeeze(2).unsqueeze(1)\n",
        "\n",
        "        weights = F.softmax(scores, dim=-1)\n",
        "        context = torch.bmm(weights, keys)\n",
        "\n",
        "        return context, weights\n",
        "\n",
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.embedding = nn.Linear(1, 64)\n",
        "        self.attention = BahdanauAttention(hidden_size)\n",
        "        self.gru = nn.GRU(154, hidden_size, batch_first=True)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_size , hidden_size  ),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, output_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
        "        batch_size = encoder_outputs.size(0)\n",
        "        decoder_input = torch.empty(batch_size, 1, 90, device=device).fill_(0)\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_outputs = []\n",
        "        attentions = []\n",
        "\n",
        "        for i in range(40):\n",
        "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
        "                decoder_input, decoder_hidden, encoder_outputs\n",
        "            )\n",
        "\n",
        "            decoder_outputs.append(decoder_output)\n",
        "            attentions.append(attn_weights)\n",
        "\n",
        "            if target_tensor is not None:\n",
        "                decoder_input = target_tensor[:, i].unsqueeze(1)\n",
        "            else:\n",
        "                decoder_input = decoder_output\n",
        "\n",
        "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "        attentions = torch.cat(attentions, dim=1)\n",
        "\n",
        "        return decoder_outputs, decoder_hidden, attentions\n",
        "\n",
        "\n",
        "    def forward_step(self, input, hidden, encoder_outputs):\n",
        "        query = hidden.permute(1, 0, 2)\n",
        "        context, attn_weights = self.attention(query, encoder_outputs)\n",
        "\n",
        "        input_gru = torch.cat((input, context), dim=2)\n",
        "\n",
        "        output, hidden = self.gru(input_gru, hidden)\n",
        "        output = self.mlp(output)\n",
        "\n",
        "        return output, hidden, attn_weights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZXORsEMLS0C"
      },
      "outputs": [],
      "source": [
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed_all(0)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "encoder = EncoderRNN(66, 64).to(device)\n",
        "decoder = AttnDecoderRNN(64, 90).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgDfX4DhLYm3"
      },
      "outputs": [],
      "source": [
        "encoder_optimizer = optim.Adam(encoder.parameters(), lr=0.0001)\n",
        "decoder_optimizer = optim.Adam(decoder.parameters(), lr=0.0001)\n",
        "criterion = nn.MSELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwL5u7aSLbtk",
        "outputId": "af519788-3d20-4cd9-90b3-ae5601410e34"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss:2.0846536585850117e-07: 100%|██████████| 10000/10000 [2:10:38<00:00,  1.28it/s]\n"
          ]
        }
      ],
      "source": [
        "bar = tqdm(range(10000))\n",
        "prevLoss = math.inf\n",
        "stopCondition = 300\n",
        "for epoch in bar:\n",
        "    encoder.train()\n",
        "    decoder.train()\n",
        "    totalLoss = 0\n",
        "    for x, y in train_dataloader:\n",
        "        input_tensor = x.float().to(device)\n",
        "        target_tensor = y.float().to(device)\n",
        "\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
        "\n",
        "        loss = criterion(decoder_outputs, target_tensor)\n",
        "        loss.backward()\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "        totalLoss += loss.item()\n",
        "    if totalLoss > prevLoss:\n",
        "        stopCondition -= 1\n",
        "    else:\n",
        "        prevLoss = totalLoss\n",
        "        stopCondition = 300\n",
        "    bar.set_description(\"loss:{}\".format(totalLoss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "go6ri2CnMCu-"
      },
      "outputs": [],
      "source": [
        "encoder.eval()\n",
        "decoder.eval()\n",
        "y_pred = []\n",
        "y_true = []\n",
        "for x, y in test_dataloader:\n",
        "    with torch.no_grad():\n",
        "        input_tensor = x.float().to(device)\n",
        "        target_tensor = y.float()\n",
        "\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden)\n",
        "\n",
        "        y_true += target_tensor.detach().cpu().data[0,:,:]\n",
        "        y_pred += decoder_outputs.detach().cpu().data[0,:,:]\n",
        "\n",
        "y_true = torch.stack(y_true)\n",
        "y_pred = torch.stack(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PU5KjU9RIQ6",
        "outputId": "47944233-e3d4-4b71-f58b-03df6950f0ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean absolute error: 0.00051\n",
            "r2 score: -2.25415\n",
            "explained variance score: -2.23265\n",
            "maximum absolute error: 23.96376\n"
          ]
        }
      ],
      "source": [
        "showScore(y_true, y_pred)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMF7XTvJXoHxcW7GIjee4uD",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}